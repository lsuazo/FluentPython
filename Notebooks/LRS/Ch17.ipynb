{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CH 17 - Concurrency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOC<a id='toc'></a>\n",
    "* [Ch17 Notes](#ch17_notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CH17 Notes <a id='ch17_notes'></a>\n",
    "[toc](#toc)\n",
    "### Concurrency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* the `requests` library by Keneth Reitz is more powerful and easier to use than urllib.request module from python 3 std library\n",
    "    * is considered a model Pythonic API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading with concurrent.futures\n",
    "* main features are `ThreadPoolExecutor` and `ProcessPoolExecutor` classes\n",
    "    - implement interfaces that allow you to submit callables for execution in different threads or processes respectively\n",
    "    - they manage an internal pool of threads or processes and a queue of tasks to be exectuted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example code:\n",
    "```\n",
    "def download_many(cc_list):\n",
    "    workers = min(MAX_WORKERS, len(cc_list))\n",
    "    with futures.ThreadPoolExecutor(workers) as executor:\n",
    "        res = executor.map(download_one, sorted(cc_list))\n",
    "        \n",
    "       return len(list(res))\n",
    "```\n",
    "\n",
    "* `executor.__exit__` method will call `executor.shutdown(wait=True)`, which will block untill all threads are done.\n",
    "* map function returns a generator that can be iterated over to retrieve the value returned by each function.\n",
    "    - if any function raised an exception, the exception would be raised when calling next on that generator\n",
    "* very often, body of the loop is refactored into a separate function when calling either sequentially or concurrently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are Futures?\n",
    "* as of python 3.4 two Futures classes: `concurrent.futures.Futures` and `asyncio.Future`\n",
    "       - an instance of either class represents a deferred computation that may or may not have completed.\n",
    "       - their state of completion can be queried, and their results (or exceptions) can be retrieved when avaialble.\n",
    "* You and I should not create them! They should be instantiated exclusively by concurrency framework.\n",
    "    - they are instantiated when some work is scheduled - this typically returns a future.\n",
    "* both have a .done() method to check if it is done - but usually you use the `.add_done_callback()` and provide a callable instead.\n",
    "* there is also a `.result()` method, which if done, returns result, or re-reaises any exceptions. \n",
    "    - if future is not done, result behavior is very different for the two future classes: concurrency.future blocks and has optional timeout, asyncio does not support timeout, and preferred is to use yield from - which doesn't work with concurrency.\n",
    "* Executor.map returns an iterator in which `__next__` calls the `result` method of each future.\n",
    "* concurrent.futures has an .as_completed() function that takes an iterable of futures and returns an iterator that yiedls futures as they are done.\n",
    "    - they are yielded in whatever order they finish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blocking I/O and the GIL\n",
    "* The CPython interpreter is not thread-safe internally, so it has a Global Interpreted Lock (GIL), which allows only one thread at a time to executed python bytecodes. That's why a single python processs usually cannot use multiple CPU cores at the same time.\n",
    "    - when we write python code, we have no control over the GIL, but a built-in function, or an extension written in C can release the GIL. (This complciates the code of the library considerably, so most authors don't do it.)\n",
    "* however all standard libray functions that perform blockin I/O release the GIL when waiting for a result from the OS. So while one Python thread is waiting for a response from the network (or other?), the blocked I/O function releases the GIL so another thread can run.\n",
    "    - time.sleep() function also releases the GIL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
